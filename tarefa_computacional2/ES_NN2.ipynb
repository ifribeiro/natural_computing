{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Melhorias**\n",
    "\n",
    "- Mostrar estrutura da rede em um grafo\n",
    "\n",
    "https://github.com/amir7d0/classification-neural-network/blob/main/ANN.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mutation(filho, a):\n",
    "    for i in range(len(filho)):\n",
    "        filho[i] += np.random.normal(0, a, size=filho[i].shape)\n",
    "    return filho\n",
    "\n",
    "def marriage(pais,p):\n",
    "    \"\"\"\n",
    "    Escolhe os pais para o casamento\n",
    "    \n",
    "    Params:\n",
    "        - pais: população de pais\n",
    "        - p: numero de pais escolhidos para o casamento\n",
    "    return:\n",
    "        - pais_escolhidos: lista de pais escolhidos\n",
    "        - indices_pais: indices dos pais escolhidos\n",
    "    \"\"\"\n",
    "    # indice dos pais\n",
    "    pais_ids = np.arange(0,len(pais))\n",
    "    # escolha p idices aleatorioamente\n",
    "    indices_pais = np.random.choice(pais_ids,size=p, replace=False)\n",
    "    # seleciona os p pais referentes aos indices\n",
    "    pais_escolhidos = [pais[i] for i in indices_pais]\n",
    "\n",
    "    return pais_escolhidos\n",
    "\n",
    "def recombination(pais):\n",
    "    filho = [np.zeros_like(p) for p in pais[0]]\n",
    "    n_layers = len(pais[0])\n",
    "    for l in range(n_layers):\n",
    "        # escolhe o pai\n",
    "        j = np.random.randint(0, len(pais))\n",
    "        pai = pais[j][l] \n",
    "        # se for a ultima camada       \n",
    "        if (l==n_layers-1):\n",
    "            # percorre vetores de pesos da ultima camada\n",
    "            for c in range(len(filho[l])):\n",
    "                # percorre valores, exceto bias\n",
    "                for ci in range(len(filho[l][c])-1):\n",
    "                    a = pai[c][:-1]\n",
    "                    filho[l][c][ci] = np.random.choice(a)\n",
    "                filho[l][c][-1] = pai[c][-1]\n",
    "        else:\n",
    "            # print (\"Atualizando camada \", l)\n",
    "            for i in range(filho[l].shape[1]-1):\n",
    "                # print (\"K máximo \", filho[l].shape[1])\n",
    "                # a ultima coluna é o bias\n",
    "                k = np.random.randint(0, filho[l].shape[1]-1)\n",
    "                # print (\"coluna k\")\n",
    "                filho[l][:, i] = pai[:, k]\n",
    "            filho[l][:, -1] = pai[:, -1]\n",
    "    return filho\n",
    "\n",
    "def initialize_population(layers, n, init='uniform'):\n",
    "    population = []\n",
    "    for i in range(n):\n",
    "        network = []\n",
    "        for layer in layers:\n",
    "            neurons, inputs =  layer.shpW\n",
    "            if init=='uniform':\n",
    "                W = np.random.uniform(size=neurons*inputs).reshape(neurons, inputs)\n",
    "            else:\n",
    "                W = np.random.randn(neurons, inputs)\n",
    "            b = np.zeros((neurons, 1))\n",
    "            p = np.concatenate([W,b], axis=1)\n",
    "            network.append(p)\n",
    "        population.append(network)\n",
    "    return population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'functions' from '/home/iran/Documentos/code/natural_computing/tarefa_computacional2/functions.py'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import neural_network as nn\n",
    "import importlib\n",
    "import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(x_train=None, x_vali=None, y_train=None, y_vali=None, epochs=50, layers=[], mu=20, lam=60, p=2, a=0.15, lograte=10, loss='bce', encoder=None):\n",
    "    \"\"\"\n",
    "    Implementa ES(mu+lam)\n",
    "    Params:\n",
    "        - x_train\n",
    "\n",
    "    Returns\n",
    "        - best: best candidate (Neural Network weights)\n",
    "        - metrics: [scores, scores_vali, acc_training, acc_validation]\n",
    "    \"\"\"\n",
    "    # para plotagem\n",
    "    scores = [] \n",
    "    scores_vali = []\n",
    "    acc_training = []\n",
    "    acc_validation = []\n",
    "    best, best_acc, best_score = None, 0, np.inf\n",
    "    # loss e acuracia da validação\n",
    "    best_score_v = best_score\n",
    "    best_acc_v = best_acc\n",
    "    population = initialize_population(layers, lam)\n",
    "    y_true = encoder.inverse_transform(y_train).flatten()\n",
    "    y_true_vali = encoder.inverse_transform(y_vali).flatten()\n",
    "\n",
    "    scores_children = list()\n",
    "    n_flag = int(epochs/2)\n",
    "    last_score = -1\n",
    "    cnt_score = 0\n",
    "    for epoch in range(epochs):        \n",
    "        scores_children = list()\n",
    "        for parent in population:\n",
    "            s, ac = functions.eval_individual(parent, layers, x_train, y_train, y_true, loss=loss, encoder=encoder)\n",
    "            s_v, ac_v = functions.eval_individual(parent, layers, x_vali, y_vali, y_true_vali, loss=loss, encoder=encoder)\n",
    "            if (s < best_score):\n",
    "                best_acc = ac\n",
    "                best_acc_v = ac_v\n",
    "\n",
    "                best_score = s\n",
    "                best_score_v = s_v\n",
    "                best = parent\n",
    "            scores_children.append(s)        \n",
    "        ranks = np.argsort(np.argsort(scores_children))\n",
    "        # seleciona os mu pais\n",
    "        children  = [population[i] for i in ranks[:mu]]\n",
    "        #scores_children = list()\n",
    "        for l in range(lam):\n",
    "            pais_marriage = marriage(population, p)\n",
    "            filho = recombination(pais_marriage)\n",
    "            filho = mutation(filho, a)\n",
    "            children.append(filho)\n",
    "        \n",
    "        if (len(scores)>=1 and best_score == scores[-1]):\n",
    "            cnt_score += 1\n",
    "        else:\n",
    "            cnt_score = 0\n",
    "        if (cnt_score==n_flag): \n",
    "            print (\"Early stopping (network stop improving)\")\n",
    "            break\n",
    "\n",
    "        scores.append(best_score)\n",
    "        scores_vali.append(best_score_v)\n",
    "        acc_training.append(best_acc)\n",
    "        acc_validation.append(best_acc_v)\n",
    "\n",
    "        \n",
    "        if (lograte > 0) and (epoch%lograte==0):\n",
    "            print (\"#:{} acc_train={:.4f} acc_val={:.4f} loss_train={:.4f} loss_val={:.4f} cnt_score {}\".format(epoch, best_acc, best_acc_v, best_score, best_score_v, cnt_score))\n",
    "        population = children\n",
    "    return best, [scores, scores_vali, acc_training, acc_validation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multicategorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = functions.load_dataset('iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, y_train, epochs, mu, lam, p, a, lograte, enc\n",
    "args_iris = [X_train, X_test, y_hot_train, y_hot_test, 20, 100, 150, 2, 0.2, enc_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definição da estrutura da rede\n",
    "layers = [nn.Layer(4, 5, 'relu'), nn.Layer(5, 3, 'softmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#:0 acc_train=0.3481 acc_val=0.2000 loss_train=0.9771 loss_val=1.0317\n",
      "#:50 acc_train=0.8370 acc_val=0.8000 loss_train=0.7285 loss_val=0.7424\n",
      "#:100 acc_train=0.6667 acc_val=0.5333 loss_train=0.6791 loss_val=0.7691\n",
      "#:150 acc_train=0.8296 acc_val=0.9333 loss_train=0.5767 loss_val=0.4944\n",
      "#:200 acc_train=0.8296 acc_val=0.9333 loss_train=0.5767 loss_val=0.4944\n",
      "Early stopping (network stop improving)\n"
     ]
    }
   ],
   "source": [
    "best, metrics = train_nn(x_train=X_train, x_vali=X_test, y_train=y_hot_train, y_vali=y_hot_test, epochs=500, \n",
    "                layers=layers, mu=100, lam=150, p=2, a=0.2, loss='cce', lograte=50,\n",
    "                encoder=enc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running exp 0\n",
      "Early stopping (network stop improving)\n",
      "10\n",
      "Running exp 1\n",
      "Early stopping (network stop improving)\n",
      "10\n",
      "Running exp 2\n",
      "Early stopping (network stop improving)\n",
      "10\n",
      "Running exp 3\n",
      "Early stopping (network stop improving)\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "functions.run_es_experiments(train_nn, 4, layers, \"es_nn_iris\", args=args_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a  0.1 loss 0.8158 accuracy 0.5900\n",
      "a  0.2 loss 0.6788 accuracy 0.6550\n",
      "a  0.3 loss 0.6316 accuracy 0.7133\n",
      "a  0.4 loss 0.5521 accuracy 0.7550\n"
     ]
    }
   ],
   "source": [
    "# TODO: aumentar tamanho da população ou da rede\n",
    "for l in [10, 15, 20]:\n",
    "    print (\"l: \", l)\n",
    "    layers = [nn.Layer(4, l, 'relu'), nn.Layer(l, 3, 'softmax')]\n",
    "    a_ = [0.1, 0.2, 0.3, 0.4]\n",
    "    for a in a_:\n",
    "        print (\"\\ta \", a, end=\" \")\n",
    "        args_iris[6] = a\n",
    "        functions.run_es_experiments(train_nn2, 4, layers, \"es_nn_iris\", args=args_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [nn.Layer(4, 10, 'relu'), nn.Layer(10, 3, 'softmax')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = functions.load_dataset('wine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_hot_train, X_test, y_hot_test, encoder = get_samples(X, Y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 2)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0], len(np.unique(y_hot_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [nn.Layer(13, 10, 'relu'), nn.Layer(10, 3, 'softmax')]\n",
    "args_wine = [X_train, X_test, y_hot_train, y_hot_test, 500, 100, 150, 2, 0.2, encoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#:0 acc_train=0.4238 acc_val=0.2593 loss_train=1.1012 loss_val=1.3620 cnt_score 0\n",
      "#:50 acc_train=0.5894 acc_val=0.4444 loss_train=0.9492 loss_val=0.9352 cnt_score 44\n",
      "#:100 acc_train=0.5894 acc_val=0.4444 loss_train=0.9492 loss_val=0.9352 cnt_score 94\n",
      "#:150 acc_train=0.5894 acc_val=0.4444 loss_train=0.9492 loss_val=0.9352 cnt_score 144\n",
      "#:200 acc_train=0.5894 acc_val=0.4444 loss_train=0.9492 loss_val=0.9352 cnt_score 194\n",
      "#:250 acc_train=0.5894 acc_val=0.4444 loss_train=0.9492 loss_val=0.9352 cnt_score 244\n",
      "Early stopping (network stop improving)\n"
     ]
    }
   ],
   "source": [
    "best, metrics = train_nn(x_train=X_train, x_vali=X_test, y_train=y_hot_train, y_vali=y_hot_test, epochs=500, \n",
    "                layers=layers, mu=60, lam=110, p=2, a=0.25, loss='cce', lograte=50,\n",
    "                encoder=encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l 2 a 0.15\n",
      "#:0 acc_train=0.4702 acc_val=0.3704 loss_train=1.0588 loss_val=1.1988 cnt_score 0\n",
      "#:100 acc_train=0.5033 acc_val=0.3333 loss_train=0.8829 loss_val=0.9724 cnt_score 21\n",
      "#:200 acc_train=0.6755 acc_val=0.5185 loss_train=0.8729 loss_val=0.9639 cnt_score 65\n",
      "#:300 acc_train=0.7086 acc_val=0.5926 loss_train=0.7832 loss_val=0.7963 cnt_score 33\n",
      "#:400 acc_train=0.7086 acc_val=0.5926 loss_train=0.7832 loss_val=0.7963 cnt_score 133\n",
      "Loss 0.7832\n",
      "l 2 a 0.25\n",
      "#:0 acc_train=0.3311 acc_val=0.3333 loss_train=1.0570 loss_val=1.1073 cnt_score 0\n",
      "#:100 acc_train=0.5762 acc_val=0.4444 loss_train=0.7781 loss_val=1.0097 cnt_score 47\n",
      "#:200 acc_train=0.6689 acc_val=0.6667 loss_train=0.6628 loss_val=0.6578 cnt_score 29\n",
      "#:300 acc_train=0.6821 acc_val=0.5926 loss_train=0.6623 loss_val=0.6230 cnt_score 99\n",
      "#:400 acc_train=0.6821 acc_val=0.5926 loss_train=0.6623 loss_val=0.6230 cnt_score 199\n",
      "Loss 0.6300\n",
      "l 2 a 0.35\n",
      "#:0 acc_train=0.3311 acc_val=0.3333 loss_train=1.0476 loss_val=1.1215 cnt_score 0\n",
      "#:100 acc_train=0.7152 acc_val=0.9259 loss_train=0.5771 loss_val=0.3768 cnt_score 41\n",
      "#:200 acc_train=0.7152 acc_val=0.9259 loss_train=0.5771 loss_val=0.3768 cnt_score 141\n",
      "#:300 acc_train=0.7152 acc_val=0.9259 loss_train=0.5771 loss_val=0.3768 cnt_score 241\n",
      "Early stopping (network stop improving)\n",
      "Loss 0.5771\n",
      "l 2 a 0.45\n",
      "#:0 acc_train=0.5762 acc_val=0.4444 loss_train=1.0508 loss_val=1.2552 cnt_score 0\n",
      "#:100 acc_train=0.6159 acc_val=0.7407 loss_train=0.7285 loss_val=0.7847 cnt_score 36\n",
      "#:200 acc_train=0.7550 acc_val=0.9259 loss_train=0.5326 loss_val=0.3058 cnt_score 80\n",
      "#:300 acc_train=0.7550 acc_val=0.9259 loss_train=0.5326 loss_val=0.3058 cnt_score 180\n",
      "Early stopping (network stop improving)\n",
      "Loss 0.5326\n",
      "l 4 a 0.15\n",
      "#:0 acc_train=0.4305 acc_val=0.3333 loss_train=0.9848 loss_val=1.0175 cnt_score 0\n",
      "#:100 acc_train=0.7020 acc_val=0.6296 loss_train=0.8741 loss_val=0.8184 cnt_score 56\n",
      "#:200 acc_train=0.7020 acc_val=0.6296 loss_train=0.8741 loss_val=0.8184 cnt_score 156\n",
      "Early stopping (network stop improving)\n",
      "Loss 0.8741\n",
      "l 4 a 0.25\n",
      "#:0 acc_train=0.3444 acc_val=0.4074 loss_train=1.0669 loss_val=1.2879 cnt_score 0\n",
      "#:100 acc_train=0.7682 acc_val=0.6296 loss_train=0.6412 loss_val=0.9147 cnt_score 40\n",
      "#:200 acc_train=0.7682 acc_val=0.6296 loss_train=0.6412 loss_val=0.9147 cnt_score 140\n",
      "#:300 acc_train=0.7682 acc_val=0.6296 loss_train=0.6412 loss_val=0.9147 cnt_score 240\n",
      "Early stopping (network stop improving)\n",
      "Loss 0.6412\n",
      "l 4 a 0.35\n",
      "#:0 acc_train=0.3311 acc_val=0.3333 loss_train=1.0964 loss_val=1.1521 cnt_score 0\n",
      "#:100 acc_train=0.6424 acc_val=0.5556 loss_train=0.7521 loss_val=0.9114 cnt_score 30\n",
      "#:200 acc_train=0.6424 acc_val=0.5556 loss_train=0.7521 loss_val=0.9114 cnt_score 130\n",
      "#:300 acc_train=0.6424 acc_val=0.5556 loss_train=0.7521 loss_val=0.9114 cnt_score 230\n",
      "Early stopping (network stop improving)\n",
      "Loss 0.7521\n",
      "l 4 a 0.45\n",
      "#:0 acc_train=0.3974 acc_val=0.2593 loss_train=1.0622 loss_val=1.1602 cnt_score 0\n",
      "#:100 acc_train=0.7881 acc_val=0.9259 loss_train=0.7206 loss_val=0.5639 cnt_score 98\n",
      "#:200 acc_train=0.7881 acc_val=0.9259 loss_train=0.7206 loss_val=0.5639 cnt_score 198\n",
      "Early stopping (network stop improving)\n",
      "Loss 0.7206\n",
      "l 6 a 0.15\n",
      "#:0 acc_train=0.3046 acc_val=0.2593 loss_train=0.9961 loss_val=1.0730 cnt_score 0\n",
      "#:100 acc_train=0.5894 acc_val=0.6667 loss_train=0.7716 loss_val=0.6747 cnt_score 9\n",
      "#:200 acc_train=0.6358 acc_val=0.5926 loss_train=0.7692 loss_val=0.6587 cnt_score 41\n",
      "#:300 acc_train=0.6358 acc_val=0.5926 loss_train=0.7692 loss_val=0.6587 cnt_score 141\n",
      "#:400 acc_train=0.6358 acc_val=0.5926 loss_train=0.7692 loss_val=0.6587 cnt_score 241\n",
      "Early stopping (network stop improving)\n",
      "Loss 0.7692\n",
      "l 6 a 0.25\n",
      "#:0 acc_train=0.3377 acc_val=0.3333 loss_train=1.0181 loss_val=1.0357 cnt_score 0\n",
      "#:100 acc_train=0.6623 acc_val=0.5185 loss_train=0.8658 loss_val=0.8974 cnt_score 40\n",
      "#:200 acc_train=0.6623 acc_val=0.5185 loss_train=0.8658 loss_val=0.8974 cnt_score 140\n",
      "#:300 acc_train=0.6623 acc_val=0.5185 loss_train=0.8658 loss_val=0.8974 cnt_score 240\n",
      "Early stopping (network stop improving)\n",
      "Loss 0.8658\n",
      "l 6 a 0.35\n",
      "#:0 acc_train=0.4768 acc_val=0.2963 loss_train=1.0382 loss_val=1.2015 cnt_score 0\n",
      "#:100 acc_train=0.6424 acc_val=0.5185 loss_train=0.8168 loss_val=1.0505 cnt_score 51\n",
      "#:200 acc_train=0.6424 acc_val=0.5185 loss_train=0.8168 loss_val=1.0505 cnt_score 151\n",
      "Early stopping (network stop improving)\n",
      "Loss 0.8168\n",
      "l 6 a 0.45\n",
      "#:0 acc_train=0.5695 acc_val=0.3704 loss_train=1.0487 loss_val=1.2757 cnt_score 0\n",
      "#:100 acc_train=0.6556 acc_val=0.5185 loss_train=0.8341 loss_val=1.0714 cnt_score 88\n",
      "#:200 acc_train=0.6556 acc_val=0.5185 loss_train=0.8341 loss_val=1.0714 cnt_score 188\n",
      "Early stopping (network stop improving)\n",
      "Loss 0.8341\n",
      "l 8 a 0.15\n",
      "#:0 acc_train=0.2252 acc_val=0.1852 loss_train=1.0300 loss_val=1.1156 cnt_score 0\n",
      "#:100 acc_train=0.6689 acc_val=0.5185 loss_train=0.8872 loss_val=1.0099 cnt_score 4\n",
      "#:200 acc_train=0.6689 acc_val=0.5185 loss_train=0.8872 loss_val=1.0099 cnt_score 104\n",
      "#:300 acc_train=0.6689 acc_val=0.5185 loss_train=0.8872 loss_val=1.0099 cnt_score 204\n",
      "Early stopping (network stop improving)\n",
      "Loss 0.8872\n",
      "l 8 a 0.25\n",
      "#:0 acc_train=0.4834 acc_val=0.4074 loss_train=1.0050 loss_val=1.1000 cnt_score 0\n",
      "#:100 acc_train=0.5629 acc_val=0.5185 loss_train=0.8722 loss_val=1.3046 cnt_score 84\n",
      "#:200 acc_train=0.5629 acc_val=0.5185 loss_train=0.8722 loss_val=1.3046 cnt_score 184\n",
      "Early stopping (network stop improving)\n",
      "Loss 0.8722\n",
      "l 8 a 0.35\n",
      "#:0 acc_train=0.4238 acc_val=0.2593 loss_train=1.0519 loss_val=1.2098 cnt_score 0\n",
      "#:100 acc_train=0.7351 acc_val=0.9259 loss_train=0.7186 loss_val=0.4808 cnt_score 90\n",
      "#:200 acc_train=0.7682 acc_val=0.7037 loss_train=0.7053 loss_val=0.6083 cnt_score 18\n",
      "#:300 acc_train=0.7682 acc_val=0.7037 loss_train=0.7053 loss_val=0.6083 cnt_score 118\n",
      "#:400 acc_train=0.7682 acc_val=0.7037 loss_train=0.7053 loss_val=0.6083 cnt_score 218\n",
      "Early stopping (network stop improving)\n",
      "Loss 0.7053\n",
      "l 8 a 0.45\n",
      "#:0 acc_train=0.3907 acc_val=0.4074 loss_train=1.0480 loss_val=1.1669 cnt_score 0\n",
      "#:100 acc_train=0.6026 acc_val=0.6667 loss_train=0.8632 loss_val=0.6860 cnt_score 95\n",
      "#:200 acc_train=0.6026 acc_val=0.6667 loss_train=0.8632 loss_val=0.6860 cnt_score 195\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4537/1170766783.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.45\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"l {} a {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         best, metrics = train_nn(x_train=X_train, x_vali=X_test, y_train=y_hot_train, y_vali=y_hot_test, epochs=500, \n\u001b[0m\u001b[1;32m      7\u001b[0m                     \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cce'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlograte\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     encoder=encoder)\n",
      "\u001b[0;32m/tmp/ipykernel_4537/861543216.py\u001b[0m in \u001b[0;36mtrain_nn\u001b[0;34m(x_train, x_vali, y_train, y_vali, epochs, layers, mu, lam, p, a, lograte, loss, encoder)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_individual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0ms_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mac_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_individual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_vali\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_vali\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true_vali\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mbest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mac\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/code/natural_computing/tarefa_computacional2/functions.py\u001b[0m in \u001b[0;36meval_individual\u001b[0;34m(individual, net_layers, x_train, y_train, y_true, loss, encoder)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindividual\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mlim_wo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindividual\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlim_wo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindividual\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mlim_w\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/code/natural_computing/tarefa_computacional2/neural_network.py\u001b[0m in \u001b[0;36mfeedforward\u001b[0;34m(self, A_prev)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeedforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_prev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA_prev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "layers_size = [2,4,6,8]\n",
    "for l in layers_size:\n",
    "    layers = [nn.Layer(13, l, 'relu'), nn.Layer(l, 3, 'softmax')]\n",
    "    for a in [0.15, 0.25, 0.35, 0.45]:\n",
    "        print (\"l {} a {}\".format(l, a))\n",
    "        best, metrics = train_nn(x_train=X_train, x_vali=X_test, y_train=y_hot_train, y_vali=y_hot_test, epochs=500, \n",
    "                    layers=layers, mu=100, lam=150, p=2, a=a, loss='cce', lograte=100,\n",
    "                    encoder=encoder)\n",
    "        print (\"Loss {:.4f}\".format(metrics[0][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#:0 acc_train=0.3311 acc_val=0.3333 loss_train=1.0377 loss_val=1.0750 cnt_score 0\n",
      "#:50 acc_train=0.6623 acc_val=0.5556 loss_train=0.8526 loss_val=1.4622 cnt_score 19\n",
      "#:100 acc_train=0.6623 acc_val=0.5556 loss_train=0.8526 loss_val=1.4622 cnt_score 69\n",
      "#:150 acc_train=0.6954 acc_val=0.5556 loss_train=0.6730 loss_val=1.0988 cnt_score 43\n",
      "#:200 acc_train=0.6954 acc_val=0.5556 loss_train=0.6730 loss_val=1.0988 cnt_score 93\n",
      "#:250 acc_train=0.6954 acc_val=0.5556 loss_train=0.6730 loss_val=1.0988 cnt_score 143\n",
      "#:300 acc_train=0.6954 acc_val=0.5556 loss_train=0.6730 loss_val=1.0988 cnt_score 193\n",
      "#:350 acc_train=0.6954 acc_val=0.5556 loss_train=0.6730 loss_val=1.0988 cnt_score 243\n",
      "Early stopping (network stop improving)\n"
     ]
    }
   ],
   "source": [
    "best, metrics = train_nn(x_train=X_train, x_vali=X_test, y_train=y_hot_train, y_vali=y_hot_test, epochs=500, \n",
    "                layers=layers, mu=60, lam=110, p=2, a=0.25, loss='cce', lograte=50,\n",
    "                encoder=encoder)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
