{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'functions' from '/home/iran/Documentos/code/natural_computing/tarefa_computacional2/functions.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import neural_network as nn\n",
    "import importlib\n",
    "import functions\n",
    "from datetime import datetime\n",
    "importlib.reload(functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection(pop, scores, k=3):\n",
    "    \"\"\"\n",
    "    Perform the selection by tournament\n",
    "    \"\"\"\n",
    "    # first random selection\n",
    "    selection_ix = np.random.randint(len(pop))\n",
    "    for ix in np.random.randint(0, len(pop), k-1):\n",
    "        # perform a tournament\n",
    "        if scores[ix][0] < scores[selection_ix][0]:\n",
    "            selection_ix = ix\n",
    "    return pop[selection_ix]\n",
    "\n",
    "def crossover(p1, p2):\n",
    "    \"\"\"\n",
    "    Perform the aritimethic crossover\n",
    "    \"\"\"\n",
    "    beta = np.random.uniform()\n",
    "    c1_p1 = [a*beta for a in p1]\n",
    "    c1_p2 = [a*(1-beta) for a in p2] \n",
    "    c1 = [a1+a2 for a1, a2 in zip(c1_p1, c1_p2)]\n",
    "\n",
    "    c2_p1 = [(1-beta)*a for a in p1]\n",
    "    c2_p2 = [beta*a for a in p2]\n",
    "    c2 = [a1+a2 for a1, a2 in zip(c2_p1, c2_p2)]\n",
    "\n",
    "    return [c1,c2]\n",
    "\n",
    "def mutation(p, r_mut, alpha):\n",
    "    \"\"\"\n",
    "    Perform the gaussian mutation\n",
    "    \"\"\"\n",
    "    new_p = []\n",
    "    for p_i in p:\n",
    "        pmutate = p_i.flatten()\n",
    "        for i in range(len(pmutate)):\n",
    "            if np.random.rand() < r_mut:\n",
    "                pmutate[i] = np.random.normal(loc=pmutate[i], scale=alpha, size=None)\n",
    "        pmutate = pmutate.reshape(p_i.shape)\n",
    "        new_p.append(pmutate)\n",
    "    return new_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA_NN(layers=None, X_train=None, X_test=None, y_train=None, y_test=None, n_iter=100, n_pop=50, r_mut=0.05, alpha=0.01, r_decr=0.001, encoder=None, loss=None, lograte=-1):\n",
    "    \"\"\"\n",
    "    Genetic Algorithm for training a NN\n",
    "\n",
    "    Params:\n",
    "        - layers: NN architeture\n",
    "        - X_train: training samples\n",
    "        - X_test: test samples\n",
    "        - y_train: labels for training samples\n",
    "        - y_test: labels for test samples\n",
    "        - n_iter: epochs of training\n",
    "        - n_pop: population size\n",
    "        - r_mut: crossover rate\n",
    "        - alpha: mutation step\n",
    "        - r_decr: decaying of alpha\n",
    "        - encoder: one hot encoder\n",
    "        - loss: loss function name (sigmoid, relu or softmax)\n",
    "        - lograte: rate to print logs\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize the population    \n",
    "    pop = functions.initialize_population(layers, n_pop)\n",
    "    # training and validation scores\n",
    "    best_eval = np.inf\n",
    "    best_eval_v = np.inf\n",
    "    # loss and accuracy history\n",
    "    hist_loss_train = []\n",
    "    hist_loss_vali = []\n",
    "    hist_acc_train = []\n",
    "    hist_acc_vali = []\n",
    "    # encodes labels\n",
    "    y_true = encoder.inverse_transform(y_train).flatten()\n",
    "    y_true_vali = encoder.inverse_transform(y_test).flatten()\n",
    "    n_flag = int(n_iter/2)\n",
    "    cnt_loss = 0\n",
    "\n",
    "    for gen in range(n_iter):\n",
    "        # evaluate all candidates in the population on training and validation\n",
    "        scores = [functions.eval_individual(p, layers, X_train, y_train, y_true, loss=loss, encoder=encoder) for p in pop]\n",
    "        scores_vali = [functions.eval_individual(p, layers, X_test, y_test, y_true_vali, loss=loss, encoder=encoder) for p in pop]\n",
    "        \n",
    "        # checks best candidate on training and validation\n",
    "        for i in range(n_pop):\n",
    "            if scores[i][0] < best_eval:\n",
    "                best, best_eval = pop[i], scores[i][0]\n",
    "                acc_training = scores[i][1]\n",
    "            if (scores_vali[i][0] < best_eval_v):\n",
    "                best_eval_v = scores_vali[i][0]\n",
    "                acc_valid = scores_vali[i][1]\n",
    "        if (gen%lograte== 0) and (lograte>0):\n",
    "            print (\"#{} | loss_train:{:.2f} | loss_vali:{:.2f} | acc_train:{:.2f} | acc_vali:{:.2f}\".format(gen, best_eval, best_eval_v, acc_training, acc_valid))\n",
    "        \n",
    "        if (len(hist_loss_train)>=1 and (best_eval == hist_loss_train[-1])):\n",
    "            cnt_loss +=1\n",
    "        else:\n",
    "            cnt_loss=0        \n",
    "        if (cnt_loss==n_flag): \n",
    "            print (\"Early stopping (network stop improving)\")\n",
    "            break\n",
    "\n",
    "        # saves scores and accuracy      \n",
    "        hist_loss_train.append(best_eval)\n",
    "        hist_loss_vali.append(best_eval_v)\n",
    "        hist_acc_train.append(acc_training)\n",
    "        hist_acc_vali.append(acc_valid)  \n",
    "              \n",
    "        # select parantes\n",
    "        selected = [selection(pop, scores) for _ in range(n_pop)]\n",
    "        # create the next generation    \n",
    "        children = list()\n",
    "        for i in range(0, n_pop, 2):\n",
    "            # get selected parents in pairs\n",
    "            p1, p2 = selected[i], selected[i+1]\n",
    "            # crossover and mutation\n",
    "            for c in crossover(p1, p2):\n",
    "                # mutation\n",
    "                c = mutation(c, r_mut, alpha)\n",
    "                # store for next generation\n",
    "                children.append(c)\n",
    "        alpha -= r_decr\n",
    "        # replace population\n",
    "        pop = children\n",
    "\n",
    "    metrics = [hist_loss_train, hist_loss_vali, hist_acc_train, hist_acc_vali]\n",
    "    return best, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_iris, y_iris = functions.load_dataset('iris')\n",
    "layers = [nn.Layer(4, 4, 'relu'), nn.Layer(4, 3, 'softmax')]\n",
    "args_iris = [X_iris, y_iris, 150, 50, 0.09, 0.25, 0, 'cce']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running exp 0\n",
      "Running exp 1\n",
      "Running exp 2\n",
      "Running exp 3\n",
      "Running exp 4\n",
      "Running exp 5\n",
      "Running exp 6\n",
      "Running exp 7\n",
      "Running exp 8\n",
      "Running exp 9\n",
      "Duration: 0:03:13.837107\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "functions.run_ga_experiments(GA_NN, 10, layers, 'iris_ga', args_iris)\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_wine, y_wine = functions.load_dataset('wine')\n",
    "out_size = len(np.unique(y_wine))\n",
    "layers_wine = [nn.Layer(X_wine.shape[1], 4, 'relu'), nn.Layer(4, out_size, 'softmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running exp 0\n",
      "Running exp 1\n",
      "Running exp 2\n",
      "Running exp 3\n",
      "Running exp 4\n",
      "Running exp 5\n",
      "Running exp 6\n",
      "Running exp 7\n",
      "Running exp 8\n",
      "Running exp 9\n",
      "Duration: 0:02:59.606321\n"
     ]
    }
   ],
   "source": [
    "args_wine = [X_wine, y_wine, 150, 50, 0.09, 0.25, 0, 'cce']\n",
    "start_time = datetime.now()\n",
    "functions.run_ga_experiments(GA_NN, 10, layers_wine, 'wine_ga', args_wine)\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_breast, y_breast = functions.load_dataset('breast')\n",
    "out_size = len(np.unique(y_breast))\n",
    "layers_breast = [nn.Layer(X_breast.shape[1], 4, 'relu'), nn.Layer(4, out_size, 'softmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running exp 0\n",
      "Running exp 1\n",
      "Running exp 2\n",
      "Running exp 3\n",
      "Running exp 4\n",
      "Running exp 5\n",
      "Running exp 6\n",
      "Running exp 7\n",
      "Running exp 8\n",
      "Running exp 9\n",
      "Duration: 0:05:14.167646\n"
     ]
    }
   ],
   "source": [
    "args_breast = [X_breast, y_breast, 150, 50, 0.09, 0.25, 0, 'cce']\n",
    "start_time = datetime.now()\n",
    "functions.run_ga_experiments(GA_NN, 10, layers_breast, 'breast_ga', args_breast)\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
